{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvj7uVcmIqHf0NT+AUYZSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablocosta/deleteRetreaveGenerate/blob/master/experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn3Tfkb_kZa2",
        "outputId": "8a4cdbed-e697-45b5-c97f-75c8bed7f6bc"
      },
      "source": [
        "!git clone https://github.com/pablocosta/deleteRetreaveGenerate\n",
        "%cd deleteRetreaveGenerate\n",
        "!pip install -r requirements.txt\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deleteRetreaveGenerate'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 266 (delta 5), reused 21 (delta 3), pack-reused 238\u001b[K\n",
            "Receiving objects: 100% (266/266), 220.37 MiB | 26.56 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "Checking out files: 100% (123/123), done.\n",
            "/content/deleteRetreaveGenerate/deleteRetreaveGenerate\n",
            "Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.2)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.16.4)\n",
            "Requirement already satisfied: Pillow==8.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (8.1.1)\n",
            "Requirement already satisfied: protobuf==3.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.0)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.12.0)\n",
            "Requirement already satisfied: tensorboardX==1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.7)\n",
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8.0->-r requirements.txt (line 5)) (57.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.3.0->-r requirements.txt (line 9)) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torchvision==0.3.0->-r requirements.txt (line 9)) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no0ok5mxvR0k",
        "outputId": "17cc3e51-d55b-4761-f097-44c7ce89d10b"
      },
      "source": [
        "!cat ./data/Ustance/pos.neg.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: ./data/Ustance/pos.neg.txt: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUD0Bn8bkFMI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byqwAAOeA_zD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d30451f-f454-440b-b4c1-e4ab3bce5e8a"
      },
      "source": [
        "#run experiment\n",
        "import sys\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import logging\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import src.evaluation as evaluation\n",
        "from src.cuda import CUDA\n",
        "import src.data as data\n",
        "import src.models as models\n",
        "\n",
        "\n",
        "overfit = False\n",
        "bleu = True\n",
        "config = json.load(open(\"./yelp_config.json\", 'r'))\n",
        "\n",
        "workingDir = config['data']['working_dir']\n",
        "\n",
        "if not os.path.exists(workingDir):\n",
        "    os.makedirs(workingDir)\n",
        "\n",
        "config_path = os.path.join(workingDir, 'config.json')\n",
        "if not os.path.exists(config_path):\n",
        "    with open(config_path, 'w') as f:\n",
        "        json.dump(config, f)\n",
        "\n",
        "# set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    filename='%s/train_log' % workingDir,\n",
        ")\n",
        "\n",
        "console = logging.StreamHandler()\n",
        "console.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "console.setFormatter(formatter)\n",
        "logging.getLogger('').addHandler(console)\n",
        "\n",
        "logging.info('Reading data ...')\n",
        "src, tgt = data.read_nmt_data(\n",
        "    src=config['data']['src'],\n",
        "    config=config,\n",
        "    tgt=config['data']['tgt'],\n",
        "    attribute_vocab=config['data']['attribute_vocab'],\n",
        "    ngram_attributes=config['data']['ngram_attributes']\n",
        ")\n",
        "\n",
        "srcTest, tgtTest = data.read_nmt_data(\n",
        "    src=config['data']['src_test'],\n",
        "    config=config,\n",
        "    tgt=config['data']['tgt_test'],\n",
        "    attribute_vocab=config['data']['attribute_vocab'],\n",
        "    ngram_attributes=config['data']['ngram_attributes'],\n",
        "    train_src=src,\n",
        "    train_tgt=tgt\n",
        ")\n",
        "logging.info('...done!')\n",
        "\n",
        "logging.info('...done!')\n",
        "\n",
        "#model configs\n",
        "\n",
        "batchSize    = config['data']['batch_size']\n",
        "maxLength    = config['data']['max_len']\n",
        "srcVocabSize = len(src['tok2id'])\n",
        "tgtVocabSize = len(tgt['tok2id'])\n",
        "\n",
        "weightMask                         = torch.ones(tgtVocabSize)\n",
        "weightMask[tgt['tok2id']['<pad>']] = 0\n",
        "lossCriterion                      = nn.CrossEntropyLoss(weight=weightMask)\n",
        "\n",
        "if CUDA:\n",
        "    weightMask    = weightMask.cuda()\n",
        "    lossCriterion = lossCriterion.cuda()\n",
        "\n",
        "torch.manual_seed(config['training']['random_seed'])\n",
        "np.random.seed(config['training']['random_seed'])\n",
        "\n",
        "\n",
        "#model definition\n",
        "\n",
        "model = models.SeqModel(\n",
        "    srcVocabSize=srcVocabSize,\n",
        "    tgtVocabSize=tgtVocabSize,\n",
        "    padIdSrc=src['tok2id']['<pad>'],\n",
        "    padIdTgt=tgt['tok2id']['<pad>'],\n",
        "    batchSize=batchSize,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "logging.info('MODEL HAS %s params' %  model.countParams())\n",
        "model, startEpoch = models.attemptLoadModel(\n",
        "    model          = model,\n",
        "    checkpointDir  = workingDir)\n",
        "\n",
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "writer = SummaryWriter(workingDir)\n",
        "\n",
        "\n",
        "if config['training']['optimizer'] == 'adam':\n",
        "    lr        = config['training']['learning_rate']\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "elif config['training']['optimizer'] == 'sgd':\n",
        "    lr        = config['training']['learning_rate']\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "else:\n",
        "    raise NotImplementedError(\"Learning method not recommend for task\")\n",
        "\n",
        "epochLoss             = []\n",
        "startSinceLastReport  = time.time()\n",
        "wordsSinceLastReport  = 0\n",
        "lossesSinceLastReport = []\n",
        "bestMetric            = 0.0\n",
        "bestEpoch             = 0\n",
        "curMetric             = 0.0 # log perplexity or BLEU\n",
        "numExamples           = min(len(src['content']), len(tgt['content']))\n",
        "numBatches            = numExamples / batchSize\n",
        "\n",
        "\n",
        "\n",
        "STEP = 0\n",
        "for epoch in range(startEpoch, config['training']['epochs']):\n",
        "    if curMetric > bestMetric:\n",
        "        # rm old checkpoint\n",
        "        for ckpt_path in glob.glob(workingDir + '/model.*'):\n",
        "            os.system(\"rm %s\" % ckpt_path)\n",
        "        # replace with new checkpoint\n",
        "        torch.save(model.state_dict(), workingDir + '/model.%s.ckpt' % epoch)\n",
        "\n",
        "        bestMetric = curMetric\n",
        "        bestEpoch  = epoch - 1\n",
        "\n",
        "    losses = []\n",
        "    for i in range(0, numExamples, batchSize):\n",
        "\n",
        "        if overfit:\n",
        "            i = 50\n",
        "\n",
        "        batchIdx = i / batchSize\n",
        "        \n",
        "        inputContent, inputAux, outPut = data.minibatch(\n",
        "            src, tgt, i, batchSize, maxLength, config['model']['model_type']\n",
        "            )\n",
        "        \n",
        "        inputLinesSrc, _, srcLens, srcMask, _ = inputContent\n",
        "        inputIdsAux, _, auxLens, auxMask, _ = inputAux\n",
        "        inputLinesTgt, outputLinesTgt, _, _, _ = outPut\n",
        "        \n",
        "        decoderLogit, decoderProbs = model(inputLinesSrc, inputLinesTgt, srcMask, srcLens,\n",
        "            inputIdsAux, auxLens, auxMask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = lossCriterion(\n",
        "            decoderLogit.contiguous().view(-1, tgtVocabSize), outputLinesTgt.view(-1)\n",
        "        )\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lossesSinceLastReport.append(loss.item())\n",
        "        epochLoss.append(loss.item())\n",
        "        loss.backward()\n",
        "        norm = nn.utils.clip_grad_norm_(model.parameters(), config['training']['max_norm'])\n",
        "\n",
        "        writer.add_scalar('stats/grad_norm', norm, STEP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if overfit or batchIdx % config['training']['batches_per_report'] == 0:\n",
        "\n",
        "            s = float(time.time() - startSinceLastReport)\n",
        "            eps = (batchSize * config['training']['batches_per_report']) / s\n",
        "            avgLoss = np.mean(lossesSinceLastReport)\n",
        "            info = (epoch, batchIdx, numBatches, eps, avgLoss, curMetric)\n",
        "            writer.add_scalar('stats/EPS', eps, STEP)\n",
        "            writer.add_scalar('stats/loss', avgLoss, STEP)\n",
        "            logging.info('EPOCH: %s ITER: %s/%s EPS: %.2f LOSS: %.4f METRIC: %.4f' % info)\n",
        "            startSinceLastReport = time.time()\n",
        "            wordsSinceLastReport = 0\n",
        "            lossesSinceLastReport = []\n",
        "\n",
        "\n",
        "        STEP += 1\n",
        "    if overfit:\n",
        "        continue\n",
        "\n",
        "    logging.info('EPOCH %s COMPLETE. EVALUATING...' % epoch)\n",
        "    \n",
        "\n",
        "    start = time.time()\n",
        "    model.eval()\n",
        "    \n",
        "    devLoss = evaluation.evaluateLpp(model, srcTest, tgtTest, config)\n",
        "\n",
        "    writer.add_scalar('eval/loss', devLoss, epoch)\n",
        "\n",
        "    if bleu and epoch >= config['training'].get('inference_start_epoch', 1):\n",
        "        curMetric, editDistance, inputs, preds, golds, auxs = evaluation.inferenceMetrics(\n",
        "            model, srcTest, tgtTest, config)\n",
        "\n",
        "        with open(workingDir + '/auxs.%s' % epoch, 'w') as f:\n",
        "            f.write('\\n'.join(auxs) + '\\n')\n",
        "        with open(workingDir + '/inputs.%s' % epoch, 'w') as f:\n",
        "            f.write('\\n'.join(inputs) + '\\n')\n",
        "        with open(workingDir + '/preds.%s' % epoch, 'w') as f:\n",
        "            f.write('\\n'.join(preds) + '\\n')\n",
        "        with open(workingDir + '/golds.%s' % epoch, 'w') as f:\n",
        "            f.write('\\n'.join(golds) + '\\n')\n",
        "\n",
        "        writer.add_scalar('eval/edit_distance', editDistance, epoch)\n",
        "        writer.add_scalar('eval/bleu', curMetric, epoch)\n",
        "\n",
        "    else:\n",
        "        cur_metric = devLoss\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    logging.info('METRIC: %s. TIME: %.2fs CHECKPOINTING...' % (\n",
        "        curMetric, (time.time() - start)))\n",
        "    avgLoss = np.mean(epochLoss)\n",
        "    epochLoss = []\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:08:06,515 - INFO - Reading data ...\n",
            "2021-07-07 17:08:34,545 - INFO - ...done!\n",
            "2021-07-07 17:08:34,547 - INFO - ...done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "2021-07-07 17:08:36,949 - INFO - MODEL HAS 9181445 params\n",
            "2021-07-07 17:08:37,081 - INFO - EPOCH: 0 ITER: 0.0/692.2578125 EPS: 458793.44 LOSS: 9.1708 METRIC: 0.0000\n",
            "2021-07-07 17:08:46,307 - INFO - EPOCH: 0 ITER: 200.0/692.2578125 EPS: 5550.42 LOSS: 5.7927 METRIC: 0.0000\n",
            "2021-07-07 17:08:55,517 - INFO - EPOCH: 0 ITER: 400.0/692.2578125 EPS: 5560.37 LOSS: 5.0524 METRIC: 0.0000\n",
            "2021-07-07 17:09:04,689 - INFO - EPOCH: 0 ITER: 600.0/692.2578125 EPS: 5582.99 LOSS: 4.8063 METRIC: 0.0000\n",
            "2021-07-07 17:09:08,930 - INFO - EPOCH 0 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:09:08,984 - INFO - METRIC: 0.0. TIME: 0.05s CHECKPOINTING...\n",
            "2021-07-07 17:09:09,035 - INFO - EPOCH: 1 ITER: 0.0/692.2578125 EPS: 11786.72 LOSS: 4.5929 METRIC: 0.0000\n",
            "2021-07-07 17:09:18,214 - INFO - EPOCH: 1 ITER: 200.0/692.2578125 EPS: 5579.07 LOSS: 4.3767 METRIC: 0.0000\n",
            "2021-07-07 17:09:28,015 - INFO - EPOCH: 1 ITER: 400.0/692.2578125 EPS: 5224.78 LOSS: 4.1506 METRIC: 0.0000\n",
            "2021-07-07 17:09:37,191 - INFO - EPOCH: 1 ITER: 600.0/692.2578125 EPS: 5581.11 LOSS: 3.9426 METRIC: 0.0000\n",
            "2021-07-07 17:09:41,422 - INFO - EPOCH 1 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:09:55,980 - INFO - METRIC: 1.6151974366083746. TIME: 14.56s CHECKPOINTING...\n",
            "2021-07-07 17:09:56,173 - INFO - EPOCH: 2 ITER: 0.0/692.2578125 EPS: 2697.49 LOSS: 3.7895 METRIC: 1.6152\n",
            "2021-07-07 17:10:05,432 - INFO - EPOCH: 2 ITER: 200.0/692.2578125 EPS: 5530.68 LOSS: 3.7266 METRIC: 1.6152\n",
            "2021-07-07 17:10:14,663 - INFO - EPOCH: 2 ITER: 400.0/692.2578125 EPS: 5548.23 LOSS: 3.5867 METRIC: 1.6152\n",
            "2021-07-07 17:10:23,854 - INFO - EPOCH: 2 ITER: 600.0/692.2578125 EPS: 5571.46 LOSS: 3.4787 METRIC: 1.6152\n",
            "2021-07-07 17:10:28,095 - INFO - EPOCH 2 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:10:42,508 - INFO - METRIC: 2.5511577080801695. TIME: 14.41s CHECKPOINTING...\n",
            "2021-07-07 17:10:42,690 - INFO - EPOCH: 3 ITER: 0.0/692.2578125 EPS: 2718.51 LOSS: 3.3667 METRIC: 2.5512\n",
            "2021-07-07 17:10:51,899 - INFO - EPOCH: 3 ITER: 200.0/692.2578125 EPS: 5560.90 LOSS: 3.3384 METRIC: 2.5512\n",
            "2021-07-07 17:11:01,089 - INFO - EPOCH: 3 ITER: 400.0/692.2578125 EPS: 5572.48 LOSS: 3.2442 METRIC: 2.5512\n",
            "2021-07-07 17:11:10,316 - INFO - EPOCH: 3 ITER: 600.0/692.2578125 EPS: 5550.05 LOSS: 3.1596 METRIC: 2.5512\n",
            "2021-07-07 17:11:14,535 - INFO - EPOCH 3 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:11:28,851 - INFO - METRIC: 3.167290665322437. TIME: 14.31s CHECKPOINTING...\n",
            "2021-07-07 17:11:29,039 - INFO - EPOCH: 4 ITER: 0.0/692.2578125 EPS: 2734.84 LOSS: 3.0743 METRIC: 3.1673\n",
            "2021-07-07 17:11:38,282 - INFO - EPOCH: 4 ITER: 200.0/692.2578125 EPS: 5540.75 LOSS: 3.0498 METRIC: 3.1673\n",
            "2021-07-07 17:11:47,464 - INFO - EPOCH: 4 ITER: 400.0/692.2578125 EPS: 5577.77 LOSS: 2.9370 METRIC: 3.1673\n",
            "2021-07-07 17:11:56,686 - INFO - EPOCH: 4 ITER: 600.0/692.2578125 EPS: 5552.86 LOSS: 2.9022 METRIC: 3.1673\n",
            "2021-07-07 17:12:00,936 - INFO - EPOCH 4 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:12:15,200 - INFO - METRIC: 3.8436157660167733. TIME: 14.26s CHECKPOINTING...\n",
            "2021-07-07 17:12:15,386 - INFO - EPOCH: 5 ITER: 0.0/692.2578125 EPS: 2738.19 LOSS: 2.8199 METRIC: 3.8436\n",
            "2021-07-07 17:12:24,623 - INFO - EPOCH: 5 ITER: 200.0/692.2578125 EPS: 5544.07 LOSS: 2.8338 METRIC: 3.8436\n",
            "2021-07-07 17:12:34,500 - INFO - EPOCH: 5 ITER: 400.0/692.2578125 EPS: 5184.80 LOSS: 2.7631 METRIC: 3.8436\n",
            "2021-07-07 17:12:43,746 - INFO - EPOCH: 5 ITER: 600.0/692.2578125 EPS: 5540.49 LOSS: 2.6907 METRIC: 3.8436\n",
            "2021-07-07 17:12:47,967 - INFO - EPOCH 5 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:13:02,283 - INFO - METRIC: 4.425431556382094. TIME: 14.31s CHECKPOINTING...\n",
            "2021-07-07 17:13:02,466 - INFO - EPOCH: 6 ITER: 0.0/692.2578125 EPS: 2735.35 LOSS: 2.6379 METRIC: 4.4254\n",
            "2021-07-07 17:13:11,725 - INFO - EPOCH: 6 ITER: 200.0/692.2578125 EPS: 5530.86 LOSS: 2.6231 METRIC: 4.4254\n",
            "2021-07-07 17:13:20,956 - INFO - EPOCH: 6 ITER: 400.0/692.2578125 EPS: 5547.09 LOSS: 2.5437 METRIC: 4.4254\n",
            "2021-07-07 17:13:30,190 - INFO - EPOCH: 6 ITER: 600.0/692.2578125 EPS: 5546.23 LOSS: 2.5027 METRIC: 4.4254\n",
            "2021-07-07 17:13:34,433 - INFO - EPOCH 6 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:13:48,760 - INFO - METRIC: 5.06247972907667. TIME: 14.33s CHECKPOINTING...\n",
            "2021-07-07 17:13:48,944 - INFO - EPOCH: 7 ITER: 0.0/692.2578125 EPS: 2730.64 LOSS: 2.4439 METRIC: 5.0625\n",
            "2021-07-07 17:13:58,173 - INFO - EPOCH: 7 ITER: 200.0/692.2578125 EPS: 5548.94 LOSS: 2.4385 METRIC: 5.0625\n",
            "2021-07-07 17:14:07,405 - INFO - EPOCH: 7 ITER: 400.0/692.2578125 EPS: 5547.04 LOSS: 2.3966 METRIC: 5.0625\n",
            "2021-07-07 17:14:16,642 - INFO - EPOCH: 7 ITER: 600.0/692.2578125 EPS: 5543.93 LOSS: 2.3495 METRIC: 5.0625\n",
            "2021-07-07 17:14:20,856 - INFO - EPOCH 7 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:14:35,236 - INFO - METRIC: 5.947313043957265. TIME: 14.38s CHECKPOINTING...\n",
            "2021-07-07 17:14:35,421 - INFO - EPOCH: 8 ITER: 0.0/692.2578125 EPS: 2726.68 LOSS: 2.3029 METRIC: 5.9473\n",
            "2021-07-07 17:14:44,636 - INFO - EPOCH: 8 ITER: 200.0/692.2578125 EPS: 5557.57 LOSS: 2.2920 METRIC: 5.9473\n",
            "2021-07-07 17:14:53,865 - INFO - EPOCH: 8 ITER: 400.0/692.2578125 EPS: 5548.68 LOSS: 2.2527 METRIC: 5.9473\n",
            "2021-07-07 17:15:03,098 - INFO - EPOCH: 8 ITER: 600.0/692.2578125 EPS: 5546.21 LOSS: 2.2180 METRIC: 5.9473\n",
            "2021-07-07 17:15:07,327 - INFO - EPOCH 8 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:15:21,645 - INFO - METRIC: 6.1886609236088175. TIME: 14.32s CHECKPOINTING...\n",
            "2021-07-07 17:15:21,834 - INFO - EPOCH: 9 ITER: 0.0/692.2578125 EPS: 2732.97 LOSS: 2.1591 METRIC: 6.1887\n",
            "2021-07-07 17:15:31,072 - INFO - EPOCH: 9 ITER: 200.0/692.2578125 EPS: 5543.65 LOSS: 2.1668 METRIC: 6.1887\n",
            "2021-07-07 17:15:40,928 - INFO - EPOCH: 9 ITER: 400.0/692.2578125 EPS: 5195.65 LOSS: 2.1359 METRIC: 6.1887\n",
            "2021-07-07 17:15:50,144 - INFO - EPOCH: 9 ITER: 600.0/692.2578125 EPS: 5556.19 LOSS: 2.0900 METRIC: 6.1887\n",
            "2021-07-07 17:15:54,378 - INFO - EPOCH 9 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:16:08,701 - INFO - METRIC: 7.066296518908807. TIME: 14.32s CHECKPOINTING...\n",
            "2021-07-07 17:16:08,884 - INFO - EPOCH: 10 ITER: 0.0/692.2578125 EPS: 2732.45 LOSS: 2.0283 METRIC: 7.0663\n",
            "2021-07-07 17:16:18,133 - INFO - EPOCH: 10 ITER: 200.0/692.2578125 EPS: 5537.04 LOSS: 2.0516 METRIC: 7.0663\n",
            "2021-07-07 17:16:27,371 - INFO - EPOCH: 10 ITER: 400.0/692.2578125 EPS: 5542.97 LOSS: 2.0105 METRIC: 7.0663\n",
            "2021-07-07 17:16:36,637 - INFO - EPOCH: 10 ITER: 600.0/692.2578125 EPS: 5528.47 LOSS: 1.9864 METRIC: 7.0663\n",
            "2021-07-07 17:16:40,854 - INFO - EPOCH 10 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:16:55,082 - INFO - METRIC: 8.12474004240489. TIME: 14.23s CHECKPOINTING...\n",
            "2021-07-07 17:16:55,269 - INFO - EPOCH: 11 ITER: 0.0/692.2578125 EPS: 2748.25 LOSS: 1.9284 METRIC: 8.1247\n",
            "2021-07-07 17:17:04,497 - INFO - EPOCH: 11 ITER: 200.0/692.2578125 EPS: 5549.30 LOSS: 1.9390 METRIC: 8.1247\n",
            "2021-07-07 17:17:13,733 - INFO - EPOCH: 11 ITER: 400.0/692.2578125 EPS: 5544.80 LOSS: 1.9190 METRIC: 8.1247\n",
            "2021-07-07 17:17:22,934 - INFO - EPOCH: 11 ITER: 600.0/692.2578125 EPS: 5565.38 LOSS: 1.8764 METRIC: 8.1247\n",
            "2021-07-07 17:17:27,190 - INFO - EPOCH 11 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:17:41,573 - INFO - METRIC: 8.593755621565462. TIME: 14.38s CHECKPOINTING...\n",
            "2021-07-07 17:17:41,770 - INFO - EPOCH: 12 ITER: 0.0/692.2578125 EPS: 2718.43 LOSS: 1.8344 METRIC: 8.5938\n",
            "2021-07-07 17:17:51,031 - INFO - EPOCH: 12 ITER: 200.0/692.2578125 EPS: 5529.83 LOSS: 1.8506 METRIC: 8.5938\n",
            "2021-07-07 17:18:00,239 - INFO - EPOCH: 12 ITER: 400.0/692.2578125 EPS: 5561.19 LOSS: 1.8333 METRIC: 8.5938\n",
            "2021-07-07 17:18:09,477 - INFO - EPOCH: 12 ITER: 600.0/692.2578125 EPS: 5545.29 LOSS: 1.8127 METRIC: 8.5938\n",
            "2021-07-07 17:18:13,684 - INFO - EPOCH 12 COMPLETE. EVALUATING...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/500..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 17:18:28,091 - INFO - METRIC: 8.828225793607809. TIME: 14.41s CHECKPOINTING...\n",
            "2021-07-07 17:18:28,277 - INFO - EPOCH: 13 ITER: 0.0/692.2578125 EPS: 2723.65 LOSS: 1.7494 METRIC: 8.8282\n",
            "2021-07-07 17:18:37,540 - INFO - EPOCH: 13 ITER: 200.0/692.2578125 EPS: 5528.66 LOSS: 1.7601 METRIC: 8.8282\n",
            "2021-07-07 17:18:47,402 - INFO - EPOCH: 13 ITER: 400.0/692.2578125 EPS: 5192.34 LOSS: 1.7431 METRIC: 8.8282\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8baec84be7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         )\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mlossesSinceLastReport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mepochLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLDTpy3D-VeO"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir working_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXryQXZxLS2H"
      },
      "source": [
        "!rm -r ./working_dir/*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}